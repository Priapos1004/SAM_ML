<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Classifier class &mdash; sam-ml-py 1.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=fc837d61"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Classifier wrapper package" href="classifier_wrappers.html" />
    <link rel="prev" title="Welcome to sam-ml-py’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            sam-ml-py
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Classifier class</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier"><code class="docutils literal notranslate"><span class="pre">Classifier</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.__init__"><code class="docutils literal notranslate"><span class="pre">Classifier.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.cross_validation"><code class="docutils literal notranslate"><span class="pre">Classifier.cross_validation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.cross_validation_small_data"><code class="docutils literal notranslate"><span class="pre">Classifier.cross_validation_small_data()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.evaluate"><code class="docutils literal notranslate"><span class="pre">Classifier.evaluate()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.evaluate_proba"><code class="docutils literal notranslate"><span class="pre">Classifier.evaluate_proba()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.evaluate_score"><code class="docutils literal notranslate"><span class="pre">Classifier.evaluate_score()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.evaluate_score_proba"><code class="docutils literal notranslate"><span class="pre">Classifier.evaluate_score_proba()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.feature_importance"><code class="docutils literal notranslate"><span class="pre">Classifier.feature_importance()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.get_random_config"><code class="docutils literal notranslate"><span class="pre">Classifier.get_random_config()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.get_random_configs"><code class="docutils literal notranslate"><span class="pre">Classifier.get_random_configs()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.grid"><code class="docutils literal notranslate"><span class="pre">Classifier.grid</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.randomCVsearch"><code class="docutils literal notranslate"><span class="pre">Classifier.randomCVsearch()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.replace_grid"><code class="docutils literal notranslate"><span class="pre">Classifier.replace_grid()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.smac_search"><code class="docutils literal notranslate"><span class="pre">Classifier.smac_search()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.train"><code class="docutils literal notranslate"><span class="pre">Classifier.train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#sam_ml.models.main_classifier.Classifier.train_warm_start"><code class="docutils literal notranslate"><span class="pre">Classifier.train_warm_start()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="classifier_wrappers.html">Classifier wrapper package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">sam-ml-py</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Classifier class</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/classifier.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-sam_ml.models.main_classifier">
<span id="classifier-class"></span><h1>Classifier class<a class="headerlink" href="#module-sam_ml.models.main_classifier" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sam_ml.models.main_classifier.</span></span><span class="sig-name descname"><span class="pre">Classifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_object=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'classifier'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'Classifier'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid:</span> <span class="pre">~ConfigSpace.configuration_space.ConfigurationSpace</span> <span class="pre">=</span> <span class="pre">Configuration</span> <span class="pre">space</span> <span class="pre">object:</span>&#160;&#160; <span class="pre">Hyperparameters:</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></p>
<p>Classifier parent class</p>
<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_object=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'classifier'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'Classifier'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid:</span> <span class="pre">~ConfigSpace.configuration_space.ConfigurationSpace</span> <span class="pre">=</span> <span class="pre">Configuration</span> <span class="pre">space</span> <span class="pre">object:</span>&#160;&#160; <span class="pre">Hyperparameters:</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.__init__" title="Link to this definition"></a></dt>
<dd><section id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>model_object<span class="classifier">classifier object</span></dt><dd><p>model with ‘fit’, ‘predict’, ‘set_params’, and ‘get_params’ method (see sklearn API)</p>
</dd>
<dt>model_name<span class="classifier">str</span></dt><dd><p>name of the model</p>
</dd>
<dt>model_type<span class="classifier">str</span></dt><dd><p>kind of estimator (e.g. ‘RFC’ for RandomForestClassifier)</p>
</dd>
<dt>grid<span class="classifier">ConfigurationSpace</span></dt><dd><p>hyperparameter grid for the model</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.cross_validation">
<span class="sig-name descname"><span class="pre">cross_validation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">console_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.cross_validation" title="Link to this definition"></a></dt>
<dd><p>Random split crossvalidation</p>
<section id="id1">
<h2>Parameters<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<dl>
<dt>X, y<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to cross validate on</p>
</dd>
<dt>cv_num<span class="classifier">int,                 default=10</span></dt><dd><p>number of different random splits</p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>console_out<span class="classifier">bool,                 default=True</span></dt><dd><p>shall the result dataframe of the different scores for the different runs be printed</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
<dt>custom_score<span class="classifier">callable,                 default=None</span></dt><dd><p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
<p>If <code class="docutils literal notranslate"><span class="pre">None</span></code>, no custom score will be calculated and also the key “custom_score” does not exist in the returned dictionary.</p>
</dd>
</dl>
</section>
<section id="returns">
<h2>Returns<a class="headerlink" href="#returns" title="Link to this heading"></a></h2>
<dl>
<dt>scores<span class="classifier">dict </span></dt><dd><p>dictionary of format:</p>
<blockquote>
<div><p>{‘accuracy’: …,
‘precision’: …,
‘recall’: …,
‘s_score’: …,
‘l_score’: …,
‘train_score’: …,
‘train_time’: …,}</p>
</div></blockquote>
<p>or if <code class="docutils literal notranslate"><span class="pre">custom_score</span> <span class="pre">!=</span> <span class="pre">None</span></code>:</p>
<blockquote>
<div><p>{‘accuracy’: …,
‘precision’: …,
‘recall’: …,
‘s_score’: …,
‘l_score’: …,
‘train_score’: …,
‘train_time’: …,
‘custom_score’: …,}</p>
</div></blockquote>
</dd>
</dl>
<p>The scores are also saved in <code class="docutils literal notranslate"><span class="pre">self.cv_scores</span></code>.</p>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># cross validate model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cross_validation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv_num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="go">                            0         1         2           average</span>
<span class="go">fit_time                    1.194662  1.295036  1.210156    1.233285</span>
<span class="go">score_time                  0.167266  0.149569  0.173546    0.163460</span>
<span class="go">test_precision (macro)      0.779381  0.809037  0.761263    0.783227</span>
<span class="go">train_precision (macro)     0.951738  0.947397  0.943044    0.947393</span>
<span class="go">test_recall (macro)         0.774488  0.800144  0.761423    0.778685</span>
<span class="go">train_recall (macro)        0.948928  0.943901  0.940066    0.944298</span>
<span class="go">test_accuracy               0.776978  0.803121  0.762305    0.780802</span>
<span class="go">train_accuracy              0.950180  0.945411  0.941212    0.945601</span>
<span class="go">test_s_score                0.923052  0.937806  0.917214    0.926024</span>
<span class="go">train_s_score               0.990794  0.990162  0.989660    0.990206</span>
<span class="go">test_l_score                0.998393  0.998836  0.998575    0.998602</span>
<span class="go">train_l_score               1.000000  1.000000  1.000000    1.000000</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.cross_validation_small_data">
<span class="sig-name descname"><span class="pre">cross_validation_small_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leave_loadbar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">console_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.cross_validation_small_data" title="Link to this definition"></a></dt>
<dd><p>One-vs-all cross validation for small datasets</p>
<p>In the cross_validation_small_data-method, the model will be trained on all datapoints except one and then tested on this last one. 
This will be repeated for all datapoints so that we have our predictions for all datapoints.</p>
<p>Advantage: optimal use of information for training</p>
<p>Disadvantage: long train time</p>
<p>This concept is very useful for small datasets (recommended: datapoints &lt; 150) because the long train time is still not too long and 
especially with a small amount of information for the model, it is important to use all the information one has for the training.</p>
<section id="id2">
<h2>Parameters<a class="headerlink" href="#id2" title="Link to this heading"></a></h2>
<dl>
<dt>X, y<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to cross validate on</p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>leave_loadbar<span class="classifier">bool,                 default=True</span></dt><dd><p>shall the loading bar of the training be visible after training (True - load bar will still be visible)</p>
</dd>
<dt>console_out<span class="classifier">bool,                 default=True</span></dt><dd><p>shall the result of the different scores and a classification_report be printed into the console</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
<dt>custom_score<span class="classifier">callable,                 default=None</span></dt><dd><p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
<p>If <code class="docutils literal notranslate"><span class="pre">None</span></code>, no custom score will be calculated and also the key “custom_score” does not exist in the returned dictionary.</p>
</dd>
</dl>
</section>
<section id="id3">
<h2>Returns<a class="headerlink" href="#id3" title="Link to this heading"></a></h2>
<dl>
<dt>scores<span class="classifier">dict </span></dt><dd><p>dictionary of format:</p>
<blockquote>
<div><p>{‘accuracy’: …,
‘precision’: …,
‘recall’: …,
‘s_score’: …,
‘l_score’: …,
‘train_score’: …,
‘train_time’: …,}</p>
</div></blockquote>
<p>or if <code class="docutils literal notranslate"><span class="pre">custom_score</span> <span class="pre">!=</span> <span class="pre">None</span></code>:</p>
<blockquote>
<div><p>{‘accuracy’: …,
‘precision’: …,
‘recall’: …,
‘s_score’: …,
‘l_score’: …,
‘train_score’: …,
‘train_time’: …,
‘custom_score’: …,}</p>
</div></blockquote>
</dd>
</dl>
<p>The scores are also saved in <code class="docutils literal notranslate"><span class="pre">self.cv_scores</span></code>.</p>
</section>
<section id="id4">
<h2>Examples<a class="headerlink" href="#id4" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># cross validate model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cross_validation_small_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">accuracy: 0.7</span>
<span class="go">precision: 0.7747221430607011</span>
<span class="go">recall: 0.672883787661406</span>
<span class="go">s_score: 0.40853182756324635</span>
<span class="go">l_score: 0.7812935895658734</span>
<span class="go">train_score: 0.9946286670687757</span>
<span class="go">train_time: 0:00:00</span>

<span class="go">classification report:</span>
<span class="go">                precision   recall  f1-score    support</span>

<span class="go">        0       0.65        0.96    0.78        82</span>
<span class="go">        1       0.90        0.38    0.54        68</span>

<span class="go">accuracy                            0.70        150</span>
<span class="go">macro avg       0.77        0.67    0.66        150</span>
<span class="go">weighted avg    0.76        0.70    0.67        150</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">console_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.evaluate" title="Link to this definition"></a></dt>
<dd><p>Function to create multiple scores with predict function of model</p>
<section id="id5">
<h2>Parameters<a class="headerlink" href="#id5" title="Link to this heading"></a></h2>
<dl>
<dt>x_test, y_test<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to evaluate model</p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>console_out<span class="classifier">bool,                 default=True</span></dt><dd><p>shall the result of the different scores and a classification_report be printed into the console</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
<dt>custom_score<span class="classifier">callable,                 default=None</span></dt><dd><p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
<p>If <code class="docutils literal notranslate"><span class="pre">None</span></code>, no custom score will be calculated and also the key “custom_score” does not exist in the returned dictionary.</p>
</dd>
</dl>
</section>
<section id="id6">
<h2>Returns<a class="headerlink" href="#id6" title="Link to this heading"></a></h2>
<dl>
<dt>scores<span class="classifier">dict </span></dt><dd><p>dictionary of format:</p>
<blockquote>
<div><p>{‘accuracy’: …,
‘precision’: …,
‘recall’: …,
‘s_score’: …,
‘l_score’: …}</p>
</div></blockquote>
<p>or if <code class="docutils literal notranslate"><span class="pre">custom_score</span> <span class="pre">!=</span> <span class="pre">None</span></code>:</p>
<blockquote>
<div><p>{‘accuracy’: …,
‘precision’: …,
‘recall’: …,
‘s_score’: …,
‘l_score’: …,
‘custom_score’: …,}</p>
</div></blockquote>
</dd>
</dl>
</section>
<section id="id7">
<h2>Examples<a class="headerlink" href="#id7" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.80</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># train and evaluate model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">accuracy: 0.802</span>
<span class="go">precision: 0.8030604133545309</span>
<span class="go">recall: 0.7957575757575757</span>
<span class="go">s_score: 0.9395778023942218</span>
<span class="go">l_score: 0.9990945415060262</span>

<span class="go">classification report: </span>
<span class="go">                precision   recall  f1-score    support</span>

<span class="go">        0       0.81        0.73    0.77        225</span>
<span class="go">        1       0.80        0.86    0.83        275</span>

<span class="go">accuracy                            0.80        500</span>
<span class="go">macro avg       0.80        0.80    0.80        500</span>
<span class="go">weighted avg    0.80        0.80    0.80        500</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.evaluate_proba">
<span class="sig-name descname"><span class="pre">evaluate_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">console_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.evaluate_proba" title="Link to this definition"></a></dt>
<dd><p>Function to create multiple scores for binary classification with predict_proba function of model</p>
<section id="id8">
<h2>Parameters<a class="headerlink" href="#id8" title="Link to this heading"></a></h2>
<dl>
<dt>x_test, y_test<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to evaluate model</p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>console_out<span class="classifier">bool,                 default=True</span></dt><dd><p>shall the result of the different scores and a classification_report be printed</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
<dt>custom_score<span class="classifier">callable,                 default=None</span></dt><dd><p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
<p>If <code class="docutils literal notranslate"><span class="pre">None</span></code>, no custom score will be calculated and also the key “custom_score” does not exist in the returned dictionary.</p>
</dd>
<dt>probability: float (0 to 1),                 default=0.5</dt><dd><p>probability for class 1 (with value 0.5 is like evaluate_score function). With increasing the probability parameter, precision will likely increase and recall will decrease (with decreasing the probability parameter, the otherway around).</p>
</dd>
</dl>
</section>
<section id="id9">
<h2>Returns<a class="headerlink" href="#id9" title="Link to this heading"></a></h2>
<dl>
<dt>scores<span class="classifier">dict </span></dt><dd><p>dictionary of format:</p>
<blockquote>
<div><p>{‘accuracy’: …,
‘precision’: …,
‘recall’: …,
‘s_score’: …,
‘l_score’: …}</p>
</div></blockquote>
<p>or if <code class="docutils literal notranslate"><span class="pre">custom_score</span> <span class="pre">!=</span> <span class="pre">None</span></code>:</p>
<blockquote>
<div><p>{‘accuracy’: …,
‘precision’: …,
‘recall’: …,
‘s_score’: …,
‘l_score’: …,
‘custom_score’: …,}</p>
</div></blockquote>
</dd>
</dl>
</section>
<section id="id10">
<h2>Examples<a class="headerlink" href="#id10" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.80</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># train and evaluate model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="go">accuracy: 0.802</span>
<span class="go">precision: 0.8030604133545309</span>
<span class="go">recall: 0.7957575757575757</span>
<span class="go">s_score: 0.9395778023942218</span>
<span class="go">l_score: 0.9990945415060262</span>

<span class="go">classification report: </span>
<span class="go">                precision   recall  f1-score    support</span>

<span class="go">        0       0.81        0.73    0.77        225</span>
<span class="go">        1       0.80        0.86    0.83        275</span>

<span class="go">accuracy                            0.80        500</span>
<span class="go">macro avg       0.80        0.80    0.80        500</span>
<span class="go">weighted avg    0.80        0.80    0.80        500</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.evaluate_score">
<span class="sig-name descname"><span class="pre">evaluate_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'accuracy'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'s_score'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'l_score'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'accuracy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.evaluate_score" title="Link to this definition"></a></dt>
<dd><p>Function to create a score with predict function of model</p>
<section id="id11">
<h2>Parameters<a class="headerlink" href="#id11" title="Link to this heading"></a></h2>
<dl>
<dt>x_test, y_test<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to evaluate model</p>
</dd>
<dt>scoring<span class="classifier">{“accuracy”, “precision”, “recall”, “s_score”, “l_score”} or callable (custom score),                 default=”accuracy”</span></dt><dd><p>metrics to evaluate the models</p>
<p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
</dl>
</section>
<section id="id12">
<h2>Returns<a class="headerlink" href="#id12" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>score<span class="classifier">float </span></dt><dd><p>metrics score value</p>
</dd>
</dl>
</section>
<section id="id13">
<h2>Examples<a class="headerlink" href="#id13" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.80</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># train and evaluate model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">recall</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate_score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;recall: </span><span class="si">{</span><span class="n">recall</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">recall: 0.4</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.evaluate_score_proba">
<span class="sig-name descname"><span class="pre">evaluate_score_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'accuracy'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'s_score'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'l_score'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'accuracy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.evaluate_score_proba" title="Link to this definition"></a></dt>
<dd><p>Function to create a score for binary classification with predict_proba function of model</p>
<section id="id14">
<h2>Parameters<a class="headerlink" href="#id14" title="Link to this heading"></a></h2>
<dl>
<dt>x_test, y_test<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to evaluate model</p>
</dd>
<dt>scoring<span class="classifier">{“accuracy”, “precision”, “recall”, “s_score”, “l_score”} or callable (custom score),                 default=”accuracy”</span></dt><dd><p>metrics to evaluate the models</p>
<p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
<dt>probability: float (0 to 1),                 default=0.5</dt><dd><p>probability for class 1 (with value 0.5 is like evaluate_score function). With increasing the probability parameter, precision will likely increase and recall will decrease (with decreasing the probability parameter, the otherway around).</p>
</dd>
</dl>
</section>
<section id="id15">
<h2>Returns<a class="headerlink" href="#id15" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>score<span class="classifier">float </span></dt><dd><p>metrics score value</p>
</dd>
</dl>
</section>
<section id="id16">
<h2>Examples<a class="headerlink" href="#id16" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.80</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># train and evaluate model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">recall</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate_score_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;recall: </span><span class="si">{</span><span class="n">recall</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">recall: 0.55</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.feature_importance">
<span class="sig-name descname"><span class="pre">feature_importance</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">show</span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.feature_importance" title="Link to this definition"></a></dt>
<dd><p>Function to generate a matplotlib plot of the top45 feature importance from the model. 
You can only use the method if you trained your model before.</p>
<section id="id17">
<h2>Returns<a class="headerlink" href="#id17" title="Link to this heading"></a></h2>
<p>plt.show object</p>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.get_random_config">
<span class="sig-name descname"><span class="pre">get_random_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.get_random_config" title="Link to this definition"></a></dt>
<dd><p>Function to generate one grid configuration</p>
<section id="id18">
<h2>Returns<a class="headerlink" href="#id18" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>config<span class="classifier">dict</span></dt><dd><p>dictionary of random parameter configuration from grid</p>
</dd>
</dl>
</section>
<section id="id19">
<h2>Examples<a class="headerlink" href="#id19" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">get_random_config</span><span class="p">()</span>
<span class="go">{&#39;C&#39;: 0.31489116479568624,</span>
<span class="go">&#39;penalty&#39;: &#39;elasticnet&#39;,</span>
<span class="go">&#39;solver&#39;: &#39;saga&#39;,</span>
<span class="go">&#39;l1_ratio&#39;: 0.6026718993550663}</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.get_random_configs">
<span class="sig-name descname"><span class="pre">get_random_configs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_trails</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.get_random_configs" title="Link to this definition"></a></dt>
<dd><p>Function to generate grid configurations</p>
<section id="id20">
<h2>Parameters<a class="headerlink" href="#id20" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>n_trails<span class="classifier">int</span></dt><dd><p>number of grid configurations</p>
</dd>
</dl>
</section>
<section id="id21">
<h2>Returns<a class="headerlink" href="#id21" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>configs<span class="classifier">list</span></dt><dd><p>list with sets of random parameter from grid</p>
</dd>
</dl>
</section>
<section id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Link to this heading"></a></h2>
<p>filter out duplicates -&gt; could be less than n_trails</p>
</section>
<section id="id22">
<h2>Examples<a class="headerlink" href="#id22" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">get_random_configs</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="go">[Configuration(values={</span>
<span class="go">    &#39;C&#39;: 1.0,</span>
<span class="go">    &#39;penalty&#39;: &#39;l2&#39;,</span>
<span class="go">    &#39;solver&#39;: &#39;lbfgs&#39;,</span>
<span class="go">}),</span>
<span class="go">Configuration(values={</span>
<span class="go">    &#39;C&#39;: 2.5378155082656657,</span>
<span class="go">    &#39;penalty&#39;: &#39;l2&#39;,</span>
<span class="go">    &#39;solver&#39;: &#39;saga&#39;,</span>
<span class="go">}),</span>
<span class="go">Configuration(values={</span>
<span class="go">    &#39;C&#39;: 2.801635158716261,</span>
<span class="go">    &#39;penalty&#39;: &#39;l2&#39;,</span>
<span class="go">    &#39;solver&#39;: &#39;lbfgs&#39;,</span>
<span class="go">})]</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.grid">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">grid</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ConfigurationSpace</span></em><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.grid" title="Link to this definition"></a></dt>
<dd><section id="id23">
<h2>Returns<a class="headerlink" href="#id23" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>grid<span class="classifier">ConfigurationSpace</span></dt><dd><p>hyperparameter tuning grid of the model</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.randomCVsearch">
<span class="sig-name descname"><span class="pre">randomCVsearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trails</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'accuracy'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'s_score'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'l_score'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'accuracy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">small_data_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leave_loadbar</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.randomCVsearch" title="Link to this definition"></a></dt>
<dd><p>Hyperparametertuning with randomCVsearch</p>
<section id="id24">
<h2>Parameters<a class="headerlink" href="#id24" title="Link to this heading"></a></h2>
<dl>
<dt>x_train, y_train<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to cross validate on</p>
</dd>
<dt>n_trails<span class="classifier">int,                 default=10</span></dt><dd><p>max number of parameter sets to test</p>
</dd>
<dt>cv_num<span class="classifier">int,                 default=5</span></dt><dd><p>number of different random splits</p>
</dd>
<dt>scoring<span class="classifier">{“accuracy”, “precision”, “recall”, “s_score”, “l_score”} or callable (custom score),                 default=”accuracy”</span></dt><dd><p>metrics to evaluate the models</p>
<p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
<dt>small_data_eval<span class="classifier">bool,                 default=False</span></dt><dd><p>if True: trains model on all datapoints except one and does this for all datapoints (recommended for datasets with less than 150 datapoints)</p>
</dd>
<dt>leave_loadbar<span class="classifier">bool,                 default=True</span></dt><dd><p>shall the loading bar of the different parameter sets be visible after training (True - load bar will still be visible)</p>
</dd>
</dl>
</section>
<section id="id25">
<h2>Returns<a class="headerlink" href="#id25" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>best_hyperparameters<span class="classifier">dict</span></dt><dd><p>best hyperparameter set</p>
</dd>
<dt>best_score<span class="classifier">float</span></dt><dd><p>the score of the best hyperparameter set</p>
</dd>
</dl>
</section>
<section id="id26">
<h2>Examples<a class="headerlink" href="#id26" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialise model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># use randomCVsearch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_hyperparam</span><span class="p">,</span> <span class="n">best_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">randomCVsearch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_trails</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cv_num</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;best hyperparameters: </span><span class="si">{</span><span class="n">best_hyperparam</span><span class="si">}</span><span class="s2">, best score: </span><span class="si">{</span><span class="n">best_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">best hyperparameters: {&#39;C&#39;: 8.471801418819979, &#39;penalty&#39;: &#39;l2&#39;, &#39;solver&#39;: &#39;newton-cg&#39;}, best score: 0.765</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.replace_grid">
<span class="sig-name descname"><span class="pre">replace_grid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_grid</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ConfigurationSpace</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.replace_grid" title="Link to this definition"></a></dt>
<dd><p>Function to replace self.grid</p>
<section id="id27">
<h2>Parameters<a class="headerlink" href="#id27" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>new_grid<span class="classifier">ConfigurationSpace</span></dt><dd><p>new grid to replace the old one with</p>
</dd>
</dl>
</section>
<section id="id28">
<h2>Returns<a class="headerlink" href="#id28" title="Link to this heading"></a></h2>
<p>changes self.grid variable</p>
</section>
<section id="id29">
<h2>Examples<a class="headerlink" href="#id29" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LDA</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_grid</span> <span class="o">=</span> <span class="n">ConfigurationSpace</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">space</span><span class="o">=</span><span class="p">{</span>
<span class="gp">... </span>        <span class="s2">&quot;solver&quot;</span><span class="p">:</span> <span class="n">Categorical</span><span class="p">(</span><span class="s2">&quot;solver&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;lsqr&quot;</span><span class="p">,</span> <span class="s2">&quot;eigen&quot;</span><span class="p">]),</span>
<span class="gp">... </span>        <span class="s2">&quot;shrinkage&quot;</span><span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="s2">&quot;shrinkage&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)),</span>
<span class="gp">... </span>    <span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">replace_grid</span><span class="p">(</span><span class="n">new_grid</span><span class="p">)</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.smac_search">
<span class="sig-name descname"><span class="pre">smac_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trails</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'accuracy'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'s_score'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'l_score'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'accuracy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">small_data_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">walltime_limit</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">600</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_level</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Configuration</span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.smac_search" title="Link to this definition"></a></dt>
<dd><p>Hyperparametertuning with SMAC library HyperparameterOptimizationFacade [can only be used in the version with swig]</p>
<p>The smac_search-method will more “intelligent” search your hyperparameter space than the randomCVsearch and 
returns the best hyperparameter set. Additionally to the n_trails parameter, it also takes a walltime_limit parameter 
that defines the maximum time in seconds that the search will take.</p>
<section id="id30">
<h2>Parameters<a class="headerlink" href="#id30" title="Link to this heading"></a></h2>
<dl>
<dt>x_train, y_train<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to cross validate on</p>
</dd>
<dt>n_trails<span class="classifier">int,                 default=50</span></dt><dd><p>max number of parameter sets to test</p>
</dd>
<dt>cv_num<span class="classifier">int,                 default=5</span></dt><dd><p>number of different random splits</p>
</dd>
<dt>scoring<span class="classifier">{“accuracy”, “precision”, “recall”, “s_score”, “l_score”} or callable (custom score),                 default=”accuracy”</span></dt><dd><p>metrics to evaluate the models</p>
<p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
<dt>small_data_eval<span class="classifier">bool,                 default=False</span></dt><dd><p>if True: trains model on all datapoints except one and does this for all datapoints (recommended for datasets with less than 150 datapoints)</p>
</dd>
<dt>walltime_limit<span class="classifier">float,                 default=500</span></dt><dd><p>the maximum time in seconds that SMAC is allowed to run</p>
</dd>
<dt>log_level<span class="classifier">int,                 default=20</span></dt><dd><p>10 - DEBUG, 20 - INFO, 30 - WARNING, 40 - ERROR, 50 - CRITICAL (SMAC3 library log levels)</p>
</dd>
</dl>
</section>
<section id="id31">
<h2>Returns<a class="headerlink" href="#id31" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>incumbent<span class="classifier">ConfigSpace.Configuration</span></dt><dd><p>ConfigSpace.Configuration with best hyperparameters (can be used like dict)</p>
</dd>
</dl>
</section>
<section id="id32">
<h2>Examples<a class="headerlink" href="#id32" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialise model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># use smac_search</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_hyperparam</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">smac_search</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_trails</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cv_num</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;best hyperparameters: </span><span class="si">{</span><span class="n">best_hyperparam</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.</span>
<span class="go">[INFO][abstract_initial_design.py:147] Using 2 initial design configurations and 0 additional configurations.</span>
<span class="go">[INFO][abstract_initial_design.py:147] Using 3 initial design configurations and 0 additional configurations.</span>
<span class="go">[INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.</span>
<span class="go">[INFO][abstract_intensifier.py:515] Added config 12be8a as new incumbent because there are no incumbents yet.</span>
<span class="go">[INFO][abstract_intensifier.py:590] Added config ce10f4 and rejected config 12be8a as incumbent because it is not better than the incumbents on 1 instances:</span>
<span class="go">[INFO][abstract_intensifier.py:590] Added config b35335 and rejected config ce10f4 as incumbent because it is not better than the incumbents on 1 instances:</span>
<span class="go">[INFO][smbo.py:327] Configuration budget is exhausted:</span>
<span class="go">[INFO][smbo.py:328] --- Remaining wallclock time: 590.5625982284546</span>
<span class="go">[INFO][smbo.py:329] --- Remaining cpu time: inf</span>
<span class="go">[INFO][smbo.py:330] --- Remaining trials: 0</span>
<span class="go">best hyperparameters: Configuration(values={</span>
<span class="go">&#39;C&#39;: 66.7049177605834,</span>
<span class="go">&#39;penalty&#39;: &#39;l2&#39;,</span>
<span class="go">&#39;solver&#39;: &#39;lbfgs&#39;,</span>
<span class="go">})</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'accuracy'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'s_score'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'l_score'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'accuracy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">console_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.train" title="Link to this definition"></a></dt>
<dd><p>Function to train the model</p>
<p>Every classifier has a train- and fit-method. They both use the fit-method of the wrapped model, 
but the train-method returns the train time and the train score of the model.</p>
<section id="id33">
<h2>Parameters<a class="headerlink" href="#id33" title="Link to this heading"></a></h2>
<dl>
<dt>x_train, y_train<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to train model</p>
</dd>
<dt>scoring<span class="classifier">{“accuracy”, “precision”, “recall”, “s_score”, “l_score”} or callable (custom score),                 default=”accuracy”</span></dt><dd><p>metrics to evaluate the models</p>
<p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
<dt>console_out<span class="classifier">bool,                 default=True</span></dt><dd><p>shall the score and time be printed out</p>
</dd>
</dl>
</section>
<section id="id34">
<h2>Returns<a class="headerlink" href="#id34" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>train_score<span class="classifier">float </span></dt><dd><p>train score value</p>
</dd>
<dt>train_time<span class="classifier">str</span></dt><dd><p>train time in format: “0:00:00” (hours:minutes:seconds)</p>
</dd>
</dl>
</section>
<section id="id35">
<h2>Examples<a class="headerlink" href="#id35" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># train model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">Train score: 0.9891840171120917 - Train time: 0:00:02</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sam_ml.models.main_classifier.Classifier.train_warm_start">
<span class="sig-name descname"><span class="pre">train_warm_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'accuracy'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'s_score'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'l_score'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'accuracy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">secondary_scoring</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'precision'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'recall'</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">console_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#sam_ml.models.main_classifier.Classifier.train_warm_start" title="Link to this definition"></a></dt>
<dd><p>Function to warm_start train the model</p>
<p>This function only differs for pipeline objects (with preprocessing) from the train method.
For pipeline objects, it only traines the preprocessing steps the first time and then only uses them to preprocess.</p>
<section id="id36">
<h2>Parameters<a class="headerlink" href="#id36" title="Link to this heading"></a></h2>
<dl>
<dt>x_train, y_train<span class="classifier">pd.DataFrame, pd.Series</span></dt><dd><p>Data to train model</p>
</dd>
<dt>scoring<span class="classifier">{“accuracy”, “precision”, “recall”, “s_score”, “l_score”} or callable (custom score),                 default=”accuracy”</span></dt><dd><p>metrics to evaluate the models</p>
<p>custom score function (or loss function) with signature
<cite>score_func(y, y_pred, **kwargs)</cite></p>
</dd>
<dt>avg<span class="classifier">{“micro”, “macro”, “binary”, “weighted”} or None,                 default=”macro”</span></dt><dd><p>average to use for precision and recall score. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned.</p>
</dd>
<dt>pos_label<span class="classifier">int or str,                 default=-1</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">avg=&quot;binary&quot;</span></code>, pos_label says which class to score. pos_label is used by s_score/l_score</p>
</dd>
<dt>secondary_scoring<span class="classifier">{“precision”, “recall”} or None,                 default=None</span></dt><dd><p>weights the scoring (only for “s_score”/”l_score”)</p>
</dd>
<dt>strength<span class="classifier">int,                 default=3</span></dt><dd><p>higher strength means a higher weight for the preferred secondary_scoring/pos_label (only for “s_score”/”l_score”)</p>
</dd>
<dt>console_out<span class="classifier">bool,                 default=True</span></dt><dd><p>shall the score and time be printed out</p>
</dd>
</dl>
</section>
<section id="id37">
<h2>Returns<a class="headerlink" href="#id37" title="Link to this heading"></a></h2>
<dl class="simple">
<dt>train_score<span class="classifier">float </span></dt><dd><p>train score value</p>
</dd>
<dt>train_time<span class="classifier">str</span></dt><dd><p>train time in format: “0:00:00” (hours:minutes:seconds)</p>
</dd>
</dl>
</section>
<section id="id38">
<h2>Examples<a class="headerlink" href="#id38" title="Link to this heading"></a></h2>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># load data (replace with own data)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># train model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sam_ml.models.classifier</span> <span class="kn">import</span> <span class="n">LR</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">LR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train_warm_start</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">Train score: 0.9891840171120917 - Train time: 0:00:02</span>
</pre></div>
</div>
</section>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to sam-ml-py’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="classifier_wrappers.html" class="btn btn-neutral float-right" title="Classifier wrapper package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Samuel Brinkmann.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>